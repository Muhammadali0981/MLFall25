{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "553c0179",
   "metadata": {},
   "source": [
    "# Lab 03 - KNN and ML Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26b1d317",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460bf1c2",
   "metadata": {},
   "source": [
    "## Task 1: Occupancy Dataset (Modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ef6b66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1 Accuracies:\n",
      "K=1: 0.9403377110694184\n",
      "K=2: 0.925328330206379\n",
      "K=3: 0.9572232645403377\n",
      "K=4: 0.9448405253283302\n",
      "K=5: 0.9553470919324578\n",
      "K=6: 0.9527204502814259\n",
      "K=7: 0.9632270168855535\n",
      "K=8: 0.9613508442776736\n",
      "K=9: 0.9647279549718574\n",
      "K=10: 0.9647279549718574\n",
      "\n",
      "Highest Accuracy: 0.9647279549718574 at K=9\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "train = pd.read_csv(r\"C:\\Ali\\Programming\\MLFall25\\Lab03\\occupancy_train.txt\", sep = \",\")\n",
    "test = pd.read_csv(r\"C:\\Ali\\Programming\\MLFall25\\Lab03\\occupancy_test.txt\", sep = \",\")\n",
    "\n",
    "# Drop unused columns (date, Temperature, CO2)\n",
    "# Attributes: date, Temperature, Humidity, Light, CO2, HumidityRatio, Occupancy\n",
    "train = train.drop(columns = [\"date\",\"Temperature\",\"CO2\"], axis=1)\n",
    "test = test.drop(columns = [\"date\",\"Temperature\",\"CO2\"], axis=1)\n",
    "\n",
    "y_train = train[\"Occupancy\"]\n",
    "X_train = train.drop(columns = [\"Occupancy\"])\n",
    "y_test = test[\"Occupancy\"]\n",
    "X_test = test.drop(columns = [\"Occupancy\"])\n",
    "\n",
    "acc = []\n",
    "print(\"Task 1 Accuracies:\")\n",
    "for n in range(1,11):\n",
    "    knn = KNeighborsClassifier(n_neighbors=n)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    acc.append(accuracy)\n",
    "    print(f\"K={n}: {accuracy}\")\n",
    "\n",
    "best_acc = max(acc)\n",
    "best_k = acc.index(best_acc) + 1\n",
    "print(f\"\\nHighest Accuracy: {best_acc} at K={best_k}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ad0391",
   "metadata": {},
   "source": [
    "## Task 2: KNN from Scratch (Chi-squared Distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "321718d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 2 Results:\n",
      "Accuracy: 0.9666666666666667\n",
      "Confusion Matrix:\n",
      "[[11  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  1  5]]\n"
     ]
    }
   ],
   "source": [
    "# Load Iris\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split 80/20\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Chi-squared distance function\n",
    "def chi_squared_distance(x1, x2):\n",
    "    # Add small epsilon to avoid division by zero\n",
    "    return 0.5 * np.sum(((x1 - x2) ** 2) / (x1 + x2 + 1e-10))\n",
    "\n",
    "# KNN Predict function\n",
    "def knn_predict(X_train, y_train, X_test, k=3):\n",
    "    y_pred = []\n",
    "    for test_point in X_test:\n",
    "        distances = []\n",
    "        for i, train_point in enumerate(X_train):\n",
    "            dist = chi_squared_distance(test_point, train_point)\n",
    "            distances.append((dist, y_train[i]))\n",
    "        \n",
    "        distances.sort(key=lambda x: x[0])\n",
    "        k_nearest = distances[:k]\n",
    "        k_nearest_labels = [label for _, label in k_nearest]\n",
    "        \n",
    "        # Majority vote\n",
    "        most_common = max(set(k_nearest_labels), key=k_nearest_labels.count)\n",
    "        y_pred.append(most_common)\n",
    "    return np.array(y_pred)\n",
    "\n",
    "# Run KNN\n",
    "k = 3\n",
    "y_pred_scratch = knn_predict(X_train, y_train, X_test, k=k)\n",
    "\n",
    "print(\"Task 2 Results:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_scratch)}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_scratch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17186bff",
   "metadata": {},
   "source": [
    "## Task 3: Comprehensive ML Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4316a7fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- EDA ---\n",
      "Missing Values:\n",
      "index                       0\n",
      "Patient Id                  0\n",
      "Age                         0\n",
      "Gender                      0\n",
      "Air Pollution               0\n",
      "Alcohol use                 0\n",
      "Dust Allergy                0\n",
      "OccuPational Hazards        0\n",
      "Genetic Risk                0\n",
      "chronic Lung Disease        0\n",
      "Balanced Diet               0\n",
      "Obesity                     0\n",
      "Smoking                     0\n",
      "Passive Smoker              0\n",
      "Chest Pain                  0\n",
      "Coughing of Blood           0\n",
      "Fatigue                     0\n",
      "Weight Loss                 0\n",
      "Shortness of Breath         0\n",
      "Wheezing                    0\n",
      "Swallowing Difficulty       0\n",
      "Clubbing of Finger Nails    0\n",
      "Frequent Cold               0\n",
      "Dry Cough                   0\n",
      "Snoring                     0\n",
      "Level                       0\n",
      "dtype: int64\n",
      "\n",
      "Duplicates: 0\n",
      "\n",
      "Target Balance (Level):\n",
      "Level\n",
      "High      365\n",
      "Medium    332\n",
      "Low       303\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Correlation with Target:\n",
      "Level_Encoded               1.000000\n",
      "Wheezing                    0.167773\n",
      "Clubbing of Finger Nails    0.116746\n",
      "Gender                      0.086222\n",
      "Age                         0.042631\n",
      "Snoring                     0.014280\n",
      "Swallowing Difficulty      -0.012880\n",
      "Weight Loss                -0.020537\n",
      "index                      -0.024556\n",
      "Shortness of Breath        -0.140178\n",
      "Frequent Cold              -0.171678\n",
      "Dry Cough                  -0.228720\n",
      "Dust Allergy               -0.264926\n",
      "OccuPational Hazards       -0.363748\n",
      "Fatigue                    -0.403276\n",
      "Genetic Risk               -0.423382\n",
      "chronic Lung Disease       -0.432405\n",
      "Alcohol use                -0.434071\n",
      "Chest Pain                 -0.494704\n",
      "Obesity                    -0.561961\n",
      "Air Pollution              -0.577269\n",
      "Smoking                    -0.611087\n",
      "Balanced Diet              -0.618781\n",
      "Coughing of Blood          -0.631118\n",
      "Passive Smoker             -0.638409\n",
      "Name: Level_Encoded, dtype: float64\n",
      "\n",
      "Split Sizes: Train=560, Val=240, Test=200\n",
      "Validation Accuracy: 1.0\n",
      "Test Accuracy: 1.0\n",
      "\n",
      "--- Metric Comparison ---\n",
      "Metric: euclidean, Test Accuracy: 1.0\n",
      "Metric: manhattan, Test Accuracy: 1.0\n",
      "Metric: chebyshev, Test Accuracy: 0.985\n",
      "\n",
      "Analysis: Different metrics may perform differently based on the data distribution. Euclidean is standard, Manhattan often works well for high dimensions, and Chebyshev for specific grid-like data.\n"
     ]
    }
   ],
   "source": [
    "# Load Dataset\n",
    "df = pd.read_csv(r\"C:\\Ali\\Programming\\MLFall25\\Lab03\\cancer patient data sets.csv\")\n",
    "\n",
    "# EDA\n",
    "print(\"--- EDA ---\")\n",
    "print(\"Missing Values:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\nDuplicates:\", df.duplicated().sum())\n",
    "\n",
    "# Handle Duplicates (if any)\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Check Balance\n",
    "print(\"\\nTarget Balance (Level):\")\n",
    "print(df['Level'].value_counts())\n",
    "\n",
    "# Feature Selection (Pearson)\n",
    "# Encode Target\n",
    "le = LabelEncoder()\n",
    "df['Level_Encoded'] = le.fit_transform(df['Level'])\n",
    "\n",
    "corr = df.corr(numeric_only=True)\n",
    "print(\"\\nCorrelation with Target:\")\n",
    "print(corr['Level_Encoded'].sort_values(ascending=False))\n",
    "\n",
    "# Select Features (Dropping non-predictive/ID columns)\n",
    "# Dropping 'index', 'Patient Id', 'Level', 'Level_Encoded'\n",
    "X = df.drop(columns=['index', 'Patient Id', 'Level', 'Level_Encoded'], errors='ignore')\n",
    "y = df['Level_Encoded']\n",
    "\n",
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split: Train 80%, Test 20%\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Validation Split: Train 70%, Val 30% (from Train split)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, test_size=0.3, random_state=0)\n",
    "\n",
    "print(f\"\\nSplit Sizes: Train={X_train.shape[0]}, Val={X_val.shape[0]}, Test={X_test.shape[0]}\")\n",
    "\n",
    "# KNN Training & Validation\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Validation Accuracy: {knn.score(X_val, y_val)}\")\n",
    "print(f\"Test Accuracy: {knn.score(X_test, y_test)}\")\n",
    "\n",
    "# Compare Metrics\n",
    "print(\"\\n--- Metric Comparison ---\")\n",
    "metrics = ['euclidean', 'manhattan', 'chebyshev']\n",
    "for m in metrics:\n",
    "    knn_m = KNeighborsClassifier(n_neighbors=5, metric=m)\n",
    "    knn_m.fit(X_train, y_train)\n",
    "    print(f\"Metric: {m}, Test Accuracy: {knn_m.score(X_test, y_test)}\")\n",
    "\n",
    "print(\"\\nAnalysis: Different metrics may perform differently based on the data distribution. Euclidean is standard, Manhattan often works well for high dimensions, and Chebyshev for specific grid-like data.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
